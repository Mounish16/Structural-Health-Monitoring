# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dBPf-eOdqyQgAy-1wD-gVswCako-2p1y
"""

import os
import numpy as np
import scipy as sio
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split



# Load Data from .mat file
def load_mat_data(F:\DSMP_Problem_H_Data.zip\DSMP_Problem_H_Data):
    mat = sio.loadmat(F:\DSMP_Problem_H_Data.zip\DSMP_Problem_H_Data)
    data_key = list(mat.keys())[-1]  # Assuming last key contains the data
    data = mat[data_key]
    return data

# Preprocessing
def preprocess_data(df):
    features = df.iloc[:, :-1].values  # Assuming last column is the label
    labels = df.iloc[:, -1].values

    scaler = StandardScaler()
    features = scaler.fit_transform(features)

    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

    return torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long), \
           torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)

# CNN-LSTM Model
class CNN_LSTM(nn.Module):
    def __init__(self, input_dim):
        super(CNN_LSTM, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.lstm = nn.LSTM(input_dim, 64, batch_first=True)
        self.fc = nn.Linear(64, 2)  # Assuming binary classification

    def forward(self, x):
        x = x.unsqueeze(1)  # Add channel dimension for CNN
        x = self.relu(self.conv1(x))
        x = x.squeeze(1)  # Remove channel dim for LSTM
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return x

# Train Model
def train_model(model, train_loader, criterion, optimizer, epochs=20):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}")

# Evaluate Model
def evaluate_model(model, test_loader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            output = model(X_batch)
            _, predicted = torch.max(output, 1)
            correct += (predicted == y_batch).sum().item()
            total += y_batch.size(0)
    print(f"Accuracy: {100 * correct / total:.2f}%")

# Main Execution
if __name__ == "__main__":
    file_path = "pair1.mat"  # Replace with actual dataset file
    df = load_data(file_path)
    X_train, y_train, X_test, y_test = preprocess_data(df)

    train_dataset = data.TensorDataset(X_train, y_train)
    test_dataset = data.TensorDataset(X_test, y_test)
    train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = CNN_LSTM(input_dim=X_train.shape[1])
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    train_model(model, train_loader, criterion, optimizer, epochs=20)
    evaluate_model(model, test_loader)