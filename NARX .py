# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pw5PWJG1aRCidsZuYzW6C182hnBdTwRz
"""

import os
import numpy as np
import scipy.io as sio
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load Data from .mat file
def load_mat_data(F:\DSMP_Problem_H_Data.zip\DSMP_Problem_H_Data):
    mat = sio.loadmat(F:\DSMP_Problem_H_Data.zip\DSMP_Problem_H_Data)
    data_key = list(mat.keys())[-1]  # Assuming last key contains the data
    data = mat[data_key]
    return data

# Preprocessing
def preprocess_data(data, input_lags=10, output_lags=1):
    X, Y = [], []
    for i in range(len(data) - input_lags - output_lags):
        X.append(data[i:i+input_lags, :-1])  # Use all columns except last as inputs
        Y.append(data[i+input_lags:i+input_lags+output_lags, -1])  # Predict last column
    X, Y = np.array(X), np.array(Y)

    scaler = StandardScaler()
    X = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)

    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

    return torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32), \
           torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)

# NARX Model
class NARX(nn.Module):
    def __init__(self, input_dim, hidden_dim=64):
        super(NARX, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 1)  # Single output prediction

    def forward(self, x):
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return x

# Train Model
def train_model(model, train_loader, criterion, optimizer, epochs=20):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}")

# Evaluate Model
def evaluate_model(model, test_loader):
    model.eval()
    predictions, actuals = [], []
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            output = model(X_batch)
            predictions.extend(output.numpy())
            actuals.extend(y_batch.numpy())

    plt.plot(actuals, label='Actual')
    plt.plot(predictions, label='Predicted')
    plt.legend()
    plt.title("NARX Prediction vs Actual")
    plt.show()

# Main Execution
if __name__ == "__main__":
    file_path = "pair2.mat"
    data = load_mat_data(F:\DSMP_Problem_H_Data.zip\DSMP_Problem_H_Data)
    X_train, y_train, X_test, y_test = preprocess_data(data)

    train_dataset = data.TensorDataset(X_train, y_train)
    test_dataset = data.TensorDataset(X_test, y_test)
    train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)

    model = NARX(input_dim=X_train.shape[2])
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    train_model(model, train_loader, criterion, optimizer, epochs=20)
    evaluate_model(model, test_loader)